{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c9067",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from scipy.stats import binned_statistic_2d\n",
    "import matplotlib.pyplot as plt\n",
    "from aib9_lib import aib9_tools as aib9\n",
    "import os\n",
    "\n",
    "# --- 1. Parameters (Must match the trained model) ---\n",
    "# It is crucial that these parameters are identical to the ones used\n",
    "# when you trained and saved the model.\n",
    "ATOM_COUNT = 58\n",
    "COORD_DIM = 3\n",
    "ORIGINAL_DIM = ATOM_COUNT * COORD_DIM\n",
    "LATENT_DIM = 4\n",
    "MODEL_PATH = 'model.pth' # The path to your saved model file\n",
    "\n",
    "# --- 2. VAE Model Definition (Must match the trained model) ---\n",
    "# This class defines the neural network architecture. You must use the\n",
    "# exact same structure as the model you saved, otherwise the saved\n",
    "# weights (the \"state dictionary\") will not match the layers.\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder Layers (Not used for generation, but needed to define the model)\n",
    "        self.fc1 = nn.Linear(ORIGINAL_DIM, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc_mean = nn.Linear(128, LATENT_DIM)\n",
    "        self.fc_log_var = nn.Linear(128, LATENT_DIM)\n",
    "\n",
    "        # Decoder Layers (This is the part we will use)\n",
    "        self.fc3 = nn.Linear(LATENT_DIM, 128)\n",
    "        self.fc4 = nn.Linear(128, 256)\n",
    "        self.fc5 = nn.Linear(256, ORIGINAL_DIM)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        return self.fc_mean(h2), self.fc_log_var(h2)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        h4 = F.relu(self.fc4(h3))\n",
    "        # Use linear activation for output coordinates\n",
    "        return self.fc5(h4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_flat = x.view(-1, ORIGINAL_DIM)\n",
    "        mu, logvar = self.encode(x_flat)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_flat = self.decode(z)\n",
    "        recon = recon_flat.view(-1, ATOM_COUNT, COORD_DIM)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "# --- 3. Generation Function ---\n",
    "def generate_samples(model, num_samples=1):\n",
    "    \"\"\"\n",
    "    Generates new samples using the decoder part of the trained VAE.\n",
    "\n",
    "    Args:\n",
    "        model (VAE): The loaded VAE model with trained weights.\n",
    "        num_samples (int): The number of new molecular samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of generated molecular coordinates.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Generating {num_samples} new sample(s) ---\")\n",
    "    \n",
    "    # Set the model to evaluation mode. This disables layers like dropout\n",
    "    # that behave differently during training vs. inference.\n",
    "    model.eval()\n",
    "\n",
    "    # We don't need to calculate gradients for generation, which saves memory and computation\n",
    "    with torch.no_grad():\n",
    "        # Determine the device the model is on (CPU or MPS)\n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "        # Sample random points from the latent space. The VAE was trained to make\n",
    "        # this space resemble a standard normal distribution (mean=0, variance=1).\n",
    "        random_latent_vectors = torch.randn(num_samples, LATENT_DIM).to(device)\n",
    "        \n",
    "        # Use the decoder to transform the latent vectors back into molecular coordinates\n",
    "        generated_samples_flat = model.decode(random_latent_vectors)\n",
    "        \n",
    "        # Reshape the flat output back to the 58x3 coordinate structure\n",
    "        generated_samples_coords = generated_samples_flat.view(num_samples, ATOM_COUNT, COORD_DIM)\n",
    "        \n",
    "        # Move the tensor to the CPU and convert it to a NumPy array for easier use\n",
    "        generated_samples_np = generated_samples_coords.cpu().numpy()\n",
    "        \n",
    "        print(f\"Successfully generated samples with final shape: {generated_samples_np.shape}\")\n",
    "        return generated_samples_np\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the device to MPS (Apple Silicon GPU) if available, otherwise CPU\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "    loaded_model = VAE().to(device)\n",
    "    print(f\"\\nLoading trained weights from '{MODEL_PATH}'...\")\n",
    "\n",
    "    try:\n",
    "        loaded_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "        print(\"Model weights loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Model file not found at '{MODEL_PATH}'.\")\n",
    "        print(\"Please make sure the 'model.pth' file is in the same directory as this script.\")\n",
    "        exit() # Exit the script if the model file is not found\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading the model: {e}\")\n",
    "        exit()\n",
    "\n",
    "    new_molecules = generate_samples(loaded_model, num_samples=1000000)\n",
    "    kai = aib9.kai_calculator(new_molecules)\n",
    "    nbins = 200\n",
    "    kai_flat = kai.reshape(-1, 2)\n",
    "    H, xedges, yedges, binnumber = binned_statistic_2d(kai_flat[:,0], kai_flat[:,1], None, statistic='count', bins=nbins)\n",
    "    H = H.T  # Transpose so that the orientation is correct\n",
    "    H = H / np.sum(H)  # Normalize to get a probability distribution\n",
    "    pmf = np.full_like(H, np.nan)\n",
    "    mask = H > 0\n",
    "    pmf[mask] = -np.log(H[mask])\n",
    "    pmf_min = np.nanmin(pmf)\n",
    "    pmf = pmf - pmf_min  \n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(pmf, origin='lower', extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], cmap='viridis', interpolation='nearest', vmin=0, vmax=8)\n",
    "    plt.colorbar(label='PMF (kT)')\n",
    "    plt.xlabel('kai1')\n",
    "    plt.ylabel('kai2')\n",
    "\n",
    "    plt.savefig('pmf.png')\n",
    "    coords =new_molecules[0]\n",
    "    view   =aib9.py3dplot(coords)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
