/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/lightning_fabric/__init__.py:40: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
wandb: Tracking run with wandb version 0.22.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /scratch/cz2200/aib9/wandb/offline-run-20251024_214928-jedmnm2j
/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:1032: UserWarning: 'NeighborEmbedding.jittable' is deprecated and a no-op. Please remove its usage.
  warnings.warn(f"'{self.__class__.__name__}.jittable' is deprecated "
/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:1032: UserWarning: 'EdgeEmbedding.jittable' is deprecated and a no-op. Please remove its usage.
  warnings.warn(f"'{self.__class__.__name__}.jittable' is deprecated "
/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:1032: UserWarning: 'ViS_MP_Vertex_Edge.jittable' is deprecated and a no-op. Please remove its usage.
  warnings.warn(f"'{self.__class__.__name__}.jittable' is deprecated "
Original data shape: (1000, 58, 3)
CV shape: (1000, 2)
Using CUDA device: Tesla V100-PCIE-32GB
CUDA memory: 34.1 GB
Successfully initialized bias for log_var outputs to: -3.00

============================================================
Starting Training - 142 samples
Model parameters: 7,352,965
Loss type: MSE (coordinate-based)
============================================================

v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
Epoch   1: Loss=nan (Recon=nan, KL=0.0001) LR=5.00e-06
  → Generating samples and visualizations...
v: torch.Size([58, 3, 256])
Traceback (most recent call last):
  File "/scratch/cz2200/aib9/train_vae_equivar.py", line 385, in <module>
    main()
  File "/scratch/cz2200/aib9/train_vae_equivar.py", line 314, in main
    metrics, figures = validate_and_sample(
  File "/scratch/cz2200/aib9/vae_utils.py", line 74, in validate_and_sample
    num_classes=model.decoder.atom_feature_dim).float().to(device)
  File "/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'EquivariantDecoder' object has no attribute 'atom_feature_dim'
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /scratch/cz2200/aib9/wandb/offline-run-20251024_214928-jedmnm2j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20251024_214928-jedmnm2j/logs[0m
