/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/lightning_fabric/__init__.py:40: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
wandb: Tracking run with wandb version 0.22.1
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /scratch/cz2200/aib9/wandb/offline-run-20251024_231840-sjcd1mds
/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:1032: UserWarning: 'NeighborEmbedding.jittable' is deprecated and a no-op. Please remove its usage.
  warnings.warn(f"'{self.__class__.__name__}.jittable' is deprecated "
/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:1032: UserWarning: 'EdgeEmbedding.jittable' is deprecated and a no-op. Please remove its usage.
  warnings.warn(f"'{self.__class__.__name__}.jittable' is deprecated "
/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:1032: UserWarning: 'ViS_MP_Vertex_Edge.jittable' is deprecated and a no-op. Please remove its usage.
  warnings.warn(f"'{self.__class__.__name__}.jittable' is deprecated "
Original data shape: (1000, 58, 3)
CV shape: (1000, 2)
Using CUDA device: Tesla V100-SXM2-32GB
CUDA memory: 34.1 GB
Successfully initialized bias for log_var outputs to: -3.00

============================================================
Starting Training - 142 samples
Model parameters: 7,287,429
Loss type: MSE (coordinate-based)
============================================================

v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 69.6433
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 75.5651
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 62.4427
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 76.5228
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 58.4323
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 71.3390
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 68.8047
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 58.4116
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 75.3646
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 73.7684
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 66.7516
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 62.8802
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 56.0801
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 62.2795
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 58.4560
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 67.4512
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 62.1656
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 69.7896
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: 67.8122
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: 0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
v: torch.Size([116, 3, 256])
  Debug - kl: 0.0001, recon_loss: nan
  Debug - μ²: 0.0001, log_var: -0.0000, exp(log_var): 1.0000
Epoch   1: Loss=nan (Recon=nan, KL=0.0001) LR=5.00e-06
  → Generating samples and visualizations...
v: torch.Size([58, 3, 256])
Traceback (most recent call last):
  File "/scratch/cz2200/aib9/train_vae_equivar.py", line 385, in <module>
    main()
  File "/scratch/cz2200/aib9/train_vae_equivar.py", line 314, in main
    metrics, figures = validate_and_sample(
  File "/scratch/cz2200/aib9/vae_utils.py", line 70, in validate_and_sample
    reconstructed = model.decoder(z_v = z, z_s = atom_types_one_hot, pos_rand = pos_rand)
  File "/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/cz2200/aib9/mse_training/vae_decoder_new.py", line 157, in forward
    v_proj = self.vector_proj(v_trans)
  File "/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/ext3/miniforge3/envs/visnet/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (7424x3 and 128x256)
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /scratch/cz2200/aib9/wandb/offline-run-20251024_231840-sjcd1mds[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20251024_231840-sjcd1mds/logs[0m
